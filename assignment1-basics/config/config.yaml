# General Setting
project_name: "CS336-TransformerLM-OpenWebText"
seed: 42
device: "cuda" # options: "cuda" or "cpu"
load_ckpt: False
save_ckpt: True

# Data Setting
train_data_path: "data/owt_train.bin"
val_data_path: "data/owt_valid.bin"
checkpoint_path: "checkpoints/"
batch_size: 16
accumulate_size: 32
context_length: 1024

# Model Setting
vocab_size: 50257
n_layers: 12
n_heads: 8
d_model: 512
d_ff: null
rope_theta: 10000.0
token_dtype: "uint16"
lr_schedule: 'wsd'
Weight_Tying: True
# Training Setting

max_learning_rate: 6e-4
min_learning_rate: 6e-5
max_steps: 2500
weight_decay: 0.1
max_grad_norm: 1.0
warmup_steps: 200
cycle_steps: 2000
log_interval: 50
eval_interval: 500
eval_steps: 50
checkpoint_interval: 500
steps_per_epoch: 1000

# Optimizer_Setting
beta1: 0.9
beta2: 0.95
eps: 1e-8
